{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - TF-IDF Classifier\n",
    "\n",
    "Ваша цель обучить классификатор который будет находить \"токсичные\" комментарии и опубликовать решения на Kaggle [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "В процессе обучения нужно ответить на ***[вопросы](https://docs.google.com/forms/d/e/1FAIpQLSd9mQx8EFpSH6FhCy1M_FmISzy3lhgyyqV3TN0pmtop7slmTA/viewform?usp=sf_link)***\n",
    "\n",
    "Данные можно скачать тут - https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../../data/Toxis comments/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../../data/Toxis comments/test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стадартными подходами для анализа текста являются [Bag of words](https://en.wikipedia.org/wiki/Bag-of-words_model) и его модификация [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf).\n",
    "\n",
    "Они реалзованны в `sklearn` в виде [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "Более подробней про них можно посмотреть [тут](https://github.com/udsclub/workshop/blob/master/notebooks/UDS-workshop-feature-extraction-and-engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуйте разные Vectorizer и разные размеры n-gramm, стоп-слова, обрезку редких слов, обрезку слишком частых слов\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                  # ngram_range=(1,2),\n",
    "                                  \n",
    "                                  # vocabulary=None,\n",
    "                                  # max_features=5000,\n",
    "                                 ) # TfidfVectorizer или CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_features = word_vectorizer.fit_transform(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What words are the most common in the dataset\n",
    "### First method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = all_word_features.todense().sum(axis=0)\n",
    "d = list(zip(word_vectorizer.get_feature_names(), sums.tolist()[0]))\n",
    "words_sorted = sorted(d, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 918456),\n",
       " ('to', 538918),\n",
       " ('of', 409932),\n",
       " ('and', 408809),\n",
       " ('you', 393819)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_sorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    \"\"\"return list of the words\"\"\"\n",
    "    pattern = r'[a-z]+'\n",
    "    words = re.findall(pattern, text.lower())\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lists = all_text.apply(get_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = dict()\n",
    "\n",
    "for item in words_lists:\n",
    "    \n",
    "    for word in list(item):\n",
    "        if word in all_words:\n",
    "            all_words[word] += 1\n",
    "        else:\n",
    "            all_words[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 919075), ('to', 539244), ('i', 434390), ('a', 412567), ('of', 410841)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 919075), ('to', 539244), ('i', 434390), ('a', 412567), ('of', 410841)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Counter(all_words)\n",
    "result.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации будем использовать логистическую регрессию [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем тренировать по одному классификатору на каждый класс. \n",
    "\n",
    "Что бы провалидировать качество модели воспользуемся функцией [cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME: toxic\n",
      "CV score for c = 0.1 is 0.9437066996329116\n",
      "CV score for c = 0.5 is 0.9638640277266323\n",
      "CV score for c = 1.0 is 0.9685395090270267\n",
      "CV score for c = 2.0 is 0.9711663234119023\n",
      "CV score for c = 3.0 is 0.9718712924035384\n",
      "CV score for c = 4.0 is 0.9720383650629912\n",
      "CV score for c = 5.0 is 0.9719888383215635\n",
      "CV score for c = 7.5 is 0.9715324572890364\n",
      "CV score for c = 10.0 is 0.9709420586166911\n",
      "--------------------\n",
      "CLASS NAME: severe_toxic\n",
      "CV score for c = 0.1 is 0.9793626417425472\n",
      "CV score for c = 0.5 is 0.9824420556705088\n",
      "CV score for c = 1.0 is 0.98319728541598\n",
      "CV score for c = 2.0 is 0.9833436514036121\n",
      "CV score for c = 3.0 is 0.9831044772559826\n",
      "CV score for c = 4.0 is 0.9827590819255781\n",
      "CV score for c = 5.0 is 0.9823828956095685\n",
      "CV score for c = 7.5 is 0.9814180154224\n",
      "CV score for c = 10.0 is 0.9805294397539411\n",
      "--------------------\n",
      "CLASS NAME: obscene\n",
      "CV score for c = 0.1 is 0.9616904209570717\n",
      "CV score for c = 0.5 is 0.9778301421837057\n",
      "CV score for c = 1.0 is 0.981616766505934\n",
      "CV score for c = 2.0 is 0.9836120684786916\n",
      "CV score for c = 3.0 is 0.9840226968666097\n",
      "CV score for c = 4.0 is 0.9840077692413001\n",
      "CV score for c = 5.0 is 0.9838345925699232\n",
      "CV score for c = 7.5 is 0.9831876641471883\n",
      "CV score for c = 10.0 is 0.9824810138063933\n",
      "--------------------\n",
      "CLASS NAME: threat\n",
      "CV score for c = 0.1 is 0.9671845722026755\n",
      "CV score for c = 0.5 is 0.9779358271942676\n",
      "CV score for c = 1.0 is 0.9822578771961116\n",
      "CV score for c = 2.0 is 0.9851155556308645\n",
      "CV score for c = 3.0 is 0.9859006599349924\n",
      "CV score for c = 4.0 is 0.986066867206978\n",
      "CV score for c = 5.0 is 0.9860429820536915\n",
      "CV score for c = 7.5 is 0.9857114947886382\n",
      "CV score for c = 10.0 is 0.9853262503010877\n",
      "--------------------\n",
      "CLASS NAME: insult\n",
      "CV score for c = 0.1 is 0.9565417489308045\n",
      "CV score for c = 0.5 is 0.9707921243777409\n",
      "CV score for c = 1.0 is 0.9741355602590079\n",
      "CV score for c = 2.0 is 0.9758211816780179\n",
      "CV score for c = 3.0 is 0.9760664727914333\n",
      "CV score for c = 4.0 is 0.9758871079624375\n",
      "CV score for c = 5.0 is 0.9755509916134392\n",
      "CV score for c = 7.5 is 0.9744887922757961\n",
      "CV score for c = 10.0 is 0.9733943934145798\n",
      "--------------------\n",
      "CLASS NAME: identity_hate\n",
      "CV score for c = 0.1 is 0.9460369992060222\n",
      "CV score for c = 0.5 is 0.9669871189620727\n",
      "CV score for c = 1.0 is 0.9713647943992112\n",
      "CV score for c = 2.0 is 0.9732889744796397\n",
      "CV score for c = 3.0 is 0.9734970019680458\n",
      "CV score for c = 4.0 is 0.9732613641195731\n",
      "CV score for c = 5.0 is 0.972889938257245\n",
      "CV score for c = 7.5 is 0.9717909833275237\n",
      "CV score for c = 10.0 is 0.9707276654781718\n",
      "--------------------\n",
      "Total score is 0.9791725092166116\n"
     ]
    }
   ],
   "source": [
    "scores= []\n",
    "# class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "c_values = [0.1, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 7.5, 10.0]\n",
    "\n",
    "class_names = class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "for class_name in class_names:\n",
    "    c_list = []\n",
    "    print('CLASS NAME: {}'.format(class_name))\n",
    "    for c in c_values:\n",
    "        \n",
    "        classifier = LogisticRegression(C=c, random_state=32)\n",
    "        \n",
    "        train_target = train[class_name]\n",
    "\n",
    "        cv_score = np.mean(cross_val_score(classifier, train_word_features, train_target, scoring='roc_auc'))\n",
    "    \n",
    "        print('CV score for c = {} is {}'.format(c, cv_score))\n",
    "        c_list.append((c, cv_score))\n",
    "        \n",
    "    scores.append(max(c_list, key=lambda x: x[1]))\n",
    "    print('-' * 20)\n",
    "\n",
    "sc = [item[1] for item in scores]\n",
    "print('Total score is {}'.format(np.mean(sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.0, 0.9720383650629912),\n",
       " (2.0, 0.9833436514036121),\n",
       " (3.0, 0.9840226968666097),\n",
       " (4.0, 0.986066867206978),\n",
       " (3.0, 0.9760664727914333),\n",
       " (3.0, 0.9734970019680458)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте подобрать лучшие параметры для `word_vectorizer` и `classifier` оптимизируя метрику [ROC AUC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опубликуйте лучшие решение на [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_dict({'id': test['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_values = [10.0, 5.0, 10.0, 10.0, 10.0, 10.0]\n",
    "c_values = [4, 2, 3, 4, 3, 3]\n",
    "\n",
    "for class_name, c in zip(class_names, c_values):\n",
    "    \n",
    "    classifier = LogisticRegression(C=c, random_state=32)\n",
    "    \n",
    "    classifier.fit(train_word_features, train[class_name])\n",
    "    # test_features = classifier.predict(test['comment text'])\n",
    "    \n",
    "    submission[class_name] = classifier.predict_proba(test_word_features)[:, 1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.176192</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.077306</td>\n",
       "      <td>0.963137</td>\n",
       "      <td>0.310109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.005550</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.016729</td>\n",
       "      <td>0.004217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.013287</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999741      0.176192  0.998271  0.077306  0.963137   \n",
       "1  0000247867823ef7  0.002221      0.001226  0.001528  0.000134  0.003660   \n",
       "2  00013b17ad220c46  0.027470      0.005550  0.013820  0.001055  0.016729   \n",
       "3  00017563c3f7919a  0.001195      0.001529  0.001585  0.000437  0.002432   \n",
       "4  00017695ad8997eb  0.013287      0.003181  0.005496  0.001278  0.006660   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.310109  \n",
       "1       0.002046  \n",
       "2       0.004217  \n",
       "3       0.000377  \n",
       "4       0.001922  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
