{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas - Toxic Comments EDA\n",
    "\n",
    "# basics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('../data/Toxis comments/test.csv')\n",
    "\n",
    "# First look\n",
    "train.head(20)\n",
    "test.head(20)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train.info()\n",
    "test.info()\n",
    "\n",
    "train.describe()\n",
    "train['toxic'].sample(10)\n",
    "train['toxic'].value_counts()\n",
    "train['toxic'].value_counts(normalize=True)\n",
    "\n",
    "train.isnull().head()\n",
    "\n",
    "print(\"Check for missing values in Train dataset\")\n",
    "null_check=train.isnull().sum()\n",
    "print(null_check)\n",
    "print(\"filling NA with \\\"unknown\\\"\")\n",
    "\n",
    "# Vizalization \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
    "plt.title(\"# per class\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type ', fontsize=12)\n",
    "\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Multi tagging\n",
    "x=rowsums.value_counts()\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize=(8,4))\n",
    "color = sns.color_palette()\n",
    "ax = sns.barplot(x.index, x.values, alpha=0.8,color=color[0])\n",
    "plt.title(\"Multiple tags per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of tags ', fontsize=12)\n",
    "\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Coorelation\n",
    "\n",
    "corr=temp_df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, annot=True, cmap=\"YlGnBu\")\n",
    "\n",
    "# Crosstab:\n",
    "pd.crosstab(temp_df['insult'], temp_df['obscene'])\n",
    "\n",
    "# look at toxic with other tags\n",
    "main_col=\"toxic\"\n",
    "corr_mats=[]\n",
    "for other_col in temp_df.columns[1:]:\n",
    "    confusion_matrix = pd.crosstab(temp_df[main_col], temp_df[other_col])\n",
    "    corr_mats.append(confusion_matrix)\n",
    "out = pd.concat(corr_mats,axis=1,keys=temp_df.columns[1:])\n",
    "out\n",
    "\n",
    "# Let's read comments\n",
    "pd.options.display.max_colwidth = -1\n",
    "train[train.toxic==1].sample(10)\n",
    "\n",
    "print(\"severe_toxic: \\n\")\n",
    "print(train[train.severe_toxic==1]['comment_text'].sample(1).iloc[0])\n",
    "\n",
    "print(\"threat: \\n\")\n",
    "print(train[train.threat==1]['comment_text'].sample(1).iloc[0])\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "\n",
    "sample=train[train.threat==1]\n",
    "\n",
    "text=sample.comment_text.values\n",
    "\n",
    "wc= WordCloud(max_font_size=60, background_color=\"black\",max_words=2000,stopwords=STOPWORDS)\n",
    "wc.generate(\" \".join(text))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc.recolor(colormap= 'viridis' , random_state=17),\n",
    "           interpolation=\"bilinear\")\n",
    "plt.show()\n",
    "\n",
    "# Feature engineering\n",
    "import re\n",
    "import string\n",
    "\n",
    "train['count_sent']=train[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n",
    "train[:2]\n",
    "\n",
    "train['count_word']=train[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "#Unique word count\n",
    "train['count_unique_word']=train[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "#Letter count\n",
    "train['count_letters']=train[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "#punctuation count\n",
    "train[\"count_punctuations\"] =train[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "#upper case words count\n",
    "train[\"count_words_upper\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "#title case words count\n",
    "train[\"count_words_title\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "#Number of stopwords\n",
    "train[\"count_stopwords\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "#Average length of the words\n",
    "train[\"mean_word_len\"] = train[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "STOPWORDS\n",
    "train.sample(2)\n",
    "\n",
    "# Word count percent in each comment:\n",
    "train['word_unique_percent']=train['count_unique_word']*100/train['count_word']\n",
    "# Punct percent in each comment:\n",
    "train['punct_percent']=train['count_punctuations']*100/train['count_word']\n",
    "\n",
    "# are longer comments more toxic\n",
    "plt.figure(figsize=(12,6))\n",
    "## sentenses\n",
    "plt.subplot(121)\n",
    "plt.suptitle(\"Are longer comments more toxic?\",fontsize=20)\n",
    "sns.violinplot(y='count_sent',x='clean', data=train, split=True)\n",
    "plt.xlabel('Clean?', fontsize=12)\n",
    "plt.ylabel('# of sentences', fontsize=12)\n",
    "plt.title(\"Number of sentences in each comment\", fontsize=15)\n",
    "# words\n",
    "plt.subplot(122)\n",
    "sns.violinplot(y='count_word',x='clean', data=train, split=True, inner=\"quart\")\n",
    "plt.xlabel('Clean?', fontsize=12)\n",
    "plt.ylabel('# of words', fontsize=12)\n",
    "plt.title(\"Number of words in each comment\", fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Spammers\n",
    "#spammers - comments with less than 40% unique words\n",
    "spammers=train[train['word_unique_percent']<30]\n",
    "\n",
    "print(\"Clean Spam example:\")\n",
    "print(spammers[spammers.clean==1].comment_text.iloc[1])\n",
    "\n",
    "print(\"Toxic Spam example:\")\n",
    "print(spammers[spammers.toxic==1].comment_text.iloc[2])\n",
    "\n",
    "#For the desired plots , the data must be in long format\n",
    "temp_df = pd.melt(train, value_vars=['count_word', 'count_unique_word'], id_vars='clean')\n",
    "\n",
    "temp_df.head()\n",
    "\n",
    "# what's so unique\n",
    "import matplotlib.gridspec as gridspec \n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.suptitle(\"What's so unique ?\",fontsize=20)\n",
    "gridspec.GridSpec(2,2)\n",
    "plt.subplot2grid((2,2),(0,0))\n",
    "sns.violinplot(x='variable', y='value', hue='clean', data=temp_df, split=True,inner='quartile')\n",
    "plt.title(\"Absolute wordcount and unique words count\")\n",
    "plt.xlabel('Feature', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "plt.subplot2grid((2,2),(0,1))\n",
    "plt.title(\"Percentage of unique words of total words in comment\")\n",
    "# sns.boxplot(x='clean', y='word_unique_percent', data=train_feats)\n",
    "ax=sns.kdeplot(train[train.clean == 0].word_unique_percent, label=\"Bad\",shade=True,color='r')\n",
    "ax=sns.kdeplot(train[train.clean == 1].word_unique_percent, label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.ylabel('Number of occurances', fontsize=12)\n",
    "plt.xlabel('Percent unique words', fontsize=12)\n",
    "\n",
    "x=spammers.iloc[:,2:8].sum()\n",
    "plt.subplot2grid((2,2),(1,0),colspan=2)\n",
    "plt.title(\"Count of comments with low(<30%) unique words\",fontsize=15)\n",
    "ax=sns.barplot(x=x.index, y=x.values,color=color[3])\n",
    "\n",
    "# adding the text labels\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Threat class', fontsize=12)\n",
    "plt.ylabel('# of comments', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Вывод: спамеры пишут более \"токсичные\" комментарии. Это будет хорошей фичей для ML\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from string import punctuation\n",
    "from wordcloud import STOPWORDS\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_\n",
    "\n",
    "csv('../../data/Toxis comments/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../../data/Toxis comments/test.csv').fillna(' ')\n",
    "\n",
    "train.shape\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "\n",
    "# to count the most common words in the comments you should set max_features=1000 to avoid MemoryError\n",
    "word_vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                  max_features=1000,\n",
    "                                 )\n",
    "\n",
    "all_word_features = word_vectorizer.fit_transform(all_text)\n",
    "x_train = word_vectorizer.transform(train_text)\n",
    "x_test = word_vectorizer.transform(test_text)\n",
    "\n",
    "sums = all_word_features.todense().sum(axis=0)\n",
    "d = list(zip(word_vectorizer.get_feature_names(), sums.tolist()[0]))\n",
    "words_sorted = sorted(d, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "words_sorted[:5]\n",
    "\n",
    "def get_words(text):\n",
    "    \"\"\"return list of the words\"\"\"\n",
    "    pattern = r'[a-z]+'\n",
    "    words = re.findall(pattern, text.lower())\n",
    "    \n",
    "    return words\n",
    "\n",
    "words_lists = all_text.apply(get_words)\n",
    "\n",
    "all_words = dict()\n",
    "\n",
    "for item in words_lists:\n",
    "    \n",
    "    for word in list(item):\n",
    "        if word in all_words:\n",
    "            all_words[word] += 1\n",
    "        else:\n",
    "            all_words[word] = 1\n",
    "            \n",
    "sorted(all_words.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "result = Counter(all_words)\n",
    "result.most_common(5)\n",
    "\n",
    "# Logistic regression\n",
    "# Для классификации будем использовать логистическую регрессию LogisticRegression.\n",
    "\n",
    "# Будем тренировать по одному классификатору на каждый класс.\n",
    "\n",
    "# Что бы провалидировать качество модели воспользуемся функцией cross_val_score\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "train['count_word']=train[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "#Unique word count\n",
    "train['count_unique_word']=train[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "#punctuation count\n",
    "train[\"count_punctuations\"] =train[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in punctuation]))\n",
    "#upper case words count\n",
    "train[\"count_words_upper\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "#Number of stopwords\n",
    "train[\"count_stopwords\"] = train[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "#Average length of the words\n",
    "train[\"mean_word_len\"] = train[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "\n",
    "#TEST\n",
    "\n",
    "test['count_word']=test[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "#Unique word count\n",
    "test['count_unique_word']=test[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "#punctuation count\n",
    "test[\"count_punctuations\"] =test[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in punctuation]))\n",
    "#upper case words count\n",
    "test[\"count_words_upper\"] = test[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "#Number of stopwords\n",
    "test[\"count_stopwords\"] = test[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "#Average length of the words\n",
    "test[\"mean_word_len\"] = test[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# create csr_matrixs\n",
    "features_train = csr_matrix(train[train.columns[-6:]].fillna(0))\n",
    "features_test = csr_matrix(test[test.columns[-6:]].fillna(0))\n",
    "\n",
    "# concatanate with the train/test_words_features\n",
    "x_train = hstack([x_train, features_train])\n",
    "x_test = hstack([x_test, features_test])\n",
    "\n",
    "scores= [] # best c_value for current class_name\n",
    "c_values = [0.1, 0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 7.5, 10.0]\n",
    "\n",
    "\n",
    "for class_name in class_names:\n",
    "    \n",
    "    c_list = []\n",
    "    print('CLASS NAME: {}'.format(class_name))\n",
    "    \n",
    "    for c in c_values:\n",
    "        classifier = LogisticRegression(C=c, random_state=32)\n",
    "        \n",
    "        y_train = train[class_name]\n",
    "        cv_score = np.mean(cross_val_score(classifier, x_train, y_train, scoring='roc_auc'))\n",
    "    \n",
    "        print('CV score for c = {} is {}'.format(c, cv_score))\n",
    "        \n",
    "        c_list.append((c, cv_score))\n",
    "        \n",
    "    scores.append(max(c_list, key=lambda x: x[1]))\n",
    "    \n",
    "    print('-' * 20)\n",
    "\n",
    "sc = [item[1] for item in scores]\n",
    "print('Total score is {}'.format(np.mean(sc)))\n",
    "\n",
    "scores\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "\n",
    "c_values = [item[0] for item in scores]\n",
    "\n",
    "for class_name, c in zip(class_names, c_values):\n",
    "    \n",
    "    classifier = LogisticRegression(C=c, random_state=32)\n",
    "    \n",
    "    y_train = train[class_name]\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    submission[class_name] = classifier.predict_proba(x_test)[:, 1]   \n",
    "    \n",
    "submission.head()\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
